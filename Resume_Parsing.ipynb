{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resume Parsing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohE2bBt4zp1s"
      },
      "source": [
        "## **Install the required python packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzrHyX3ik2Yr",
        "outputId": "ca152e62-4b2a-4f1d-926a-d671bd40b753",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install spacy"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzMF6qenk2cH",
        "outputId": "c04cc554-b6b2-4d89-d2e5-e7a6865c1481",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.3.1)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKV0KgIM6o9g",
        "outputId": "f1bcfc69-d667-4710-b0ee-7759af235e97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install docx2txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting docx2txt\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/7d/60ee3f2b16d9bfdfa72e8599470a2c1a5b759cb113c6fe1006be28359327/docx2txt-0.8.tar.gz\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-cp36-none-any.whl size=3965 sha256=430ee8e1eef5dbb0be69a990f234580876147f2b5b3d68e1f890b722992e7d8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/1f/26/a051209bbb77fc6bcfae2bb7e01fa0ff941b82292ab084d596\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-LIE4iv8WpN",
        "outputId": "6579c6c6-6430-4c25-e183-d552c30e7137",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install PyMuPDF"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyMuPDF\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/a6/4eb35955856b966add3b2232e4491643b3a9c6b83cb6c521d3f0b38b3aa8/PyMuPDF-1.18.2-cp36-cp36m-manylinux2010_x86_64.whl (6.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.3MB 2.6MB/s \n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.18.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nqHwkMElAFx",
        "outputId": "36b8219e-5139-4c95-be0b-dab7848b1621",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('words')\n",
        "nltk.download('maxent_ne_chunker')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgmamxMP_zl1"
      },
      "source": [
        "# Read form Docx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5PZtGqZ_yhT",
        "outputId": "b2e06a31-fe7f-42ba-cdc5-6e0d3bf8f795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "import docx2txt\n",
        "text = docx2txt.process(\"/content/Smith Resume.docx\")\n",
        "text"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Michael Smith\\n\\nBI / Big Data/ Azure\\n\\nManchester, UK\\n\\nEmail:- michael@gmail.com\\n\\nPhone:- 66-4445-5003\\n\\n\\n\\n10+ years of Experience in Designing, Development, Administration, Analysis, Management inthe Business Intelligence Data warehousing, Client Server Technologies, Web-based Applications, cloud solutions and Databases.\\n\\nData warehouse: Data analysis, star/ snow flake schema data modeling and design specific todata warehousing and business intelligence environment.\\n\\nDatabase: Experience in database designing, scalability, back-up and recovery, writing andoptimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes. \\n\\nCloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL Azure, StreamAnalytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure data lake analytics(U-SQL).\\n\\nBig Data: Worked Azure data lake store/analytics for big data processing and Azure data factoryto schedule U-SQL jobs. Designed and developed end to end big data solution for data insights. \\n\\n\\n\\nWilling to relocate: Anywhere\\n\\nWORK EXPERIENCESoftware Engineer\\n\\nMicrosoft - Manchester, UK.\\n\\nDecember 2015 to Present\\n\\n1. Microsoft Rewards Live dashboards:\\n\\nDescription: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping online. Microsoft Rewards members can earn points when searching with Bing, browsing with Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft rewards website. Rewards live dashboards gives a live picture of usage world-wide and by markets like US, Canada, Australia, new user registration count, top/bottom performing rewards offers, orders stats and weekly trends of user activities, orders and new user registrations. the PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes.\\n\\nTechnology/Tools used\\n\\nEvent hub, stream analytics and Power BI.\\n\\nResponsibilities\\n\\nCreated stream analytics jobs to process event hub data\\n\\nCreated Power BI live dashboard to show live usage traffic, weekly trends, cards, charts to showtop/bottom 10 offers and usage metrics.\\n\\n2. Microsoft Rewards Data Insights:\\n\\nDescription: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping online. Microsoft Rewards members can earn points when searching with Bing, browsing with Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft rewards website. Rewards data insights is data analytics and reporting platform, processes 20 million users daily activities and redemption across different markets like US, Canada, Australia.\\n\\nTechnology/Tools used\\n\\nCosmos (Microsoft big-data platform), c#, X-flow job monitoring, Power BI.\\n\\nResponsibilities\\n\\nCreated big data scripts in cosmos\\n\\nC# data extractors, processors and reducers for data transformation\\n\\nPower BI dashboards\\n\\n3. End to end tracking Tool:\\n\\nDescription: - This is real-time Tracking tool to track different business transactions like order, order response, functional acknowledgement, invoice flowing inside ICOE. It gives flexibility to customers to track their transactions and appropriate error information in-case of any failure. Based on resource based access control the tool gives flexibility to end user to perform different actions like view transactions, search based on different filter criteria and view and download actual message payload. End to end tracking tool stitches all the business transaction like order to cash flow and connects different hops inside ICOE like gateway, routing server, Processing server. It also connects different systems like ICOE, partner end point and SAP.\\n\\nTechnology/Tools used\\n\\nAzure Document db, Azure web job and Web APP, RBAC, Angular JS.\\n\\nResponsibilities\\n\\nDocument dB stored procedures.\\n\\nWeb job to process event hub data and populate Document dbâ€¢ Web App API.\\n\\nStream analytics job to transform data\\n\\nPower BI reports\\n\\n4. Biztrack Tracking Tool:\\n\\nDescription: - This is real-time Tracking tool to track different business transactions like order, order response, functional acknowledgement, invoice flowing inside ICOE. It gives flexibility to customers to track their transactions and appropriate error information in-case of any failure. Based on resource based access control the tool gives flexibility to end user to perform different actions like view transactions, search based on different filter criteria and view and download actual message payload.\\n\\nTechnology/Tools used\\n\\nSQL server 2014, SSIS, .net API, Angular JS.\\n\\nResponsibilities\\n\\nETL solution to transform business transactions data stored in Biztalk tables.\\n\\nSQL azure tables, stored procedures, User defined functions.\\n\\nPerformance tuning.\\n\\nWeb API enhancements.\\n\\n\\n\\nEDUCATION\\n\\nThe University of Manchester - UK\\n\\n2007\\n\\n\\n\\nSKILLS\\n\\nproblem solving (Less than 1 year), project lifecycle (Less than 1 year), project manager (Less than 1 year), technical assistance. (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nProfessional Skills\\n\\nExcellent analytical, problem solving, communication, knowledge transfer and interpersonalskills with ability to interact with individuals at all the levels\\n\\nQuick learner and maintains cordial relationship with project manager and team members andgood performer both in team and independent job environments\\n\\nPositive attitude towards superiors &amp; peers\\n\\nSupervised junior developers throughout project lifecycle and provided technical assistance.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTkVd3kLmCZ7"
      },
      "source": [
        "# Extract Name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D390VjphlF61",
        "outputId": "f0651347-cb2b-4aab-c8e7-518e35cd9a48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import spacy\n",
        "#import docx2txt\n",
        "# load pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "#nlp = spacy.load('en_default')\n",
        "#my_text = docx2txt.process(\"/home/waqar/CV data/Adnan.docx\")\n",
        "doc_2 = nlp(text)\n",
        "#print(doc_2.ents)\n",
        "for ent in doc_2.ents:\n",
        "    if ent.label_ == \"PERSON\":\n",
        "        print('{}'.format(ent))\n",
        "        break"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Michael Smith\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96wnA0gPlHlf"
      },
      "source": [
        "# Extract Mobile Number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRy2CgrU9bdL",
        "outputId": "8f79c1ac-0d77-467e-bfc4-2c3af553677d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import re\n",
        "\n",
        "def extract_mobile_number(text):\n",
        "    phone =  re.findall(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]', text)\n",
        "    if phone:\n",
        "        number = ''.join(phone[0])\n",
        "        if len(number) > 10:\n",
        "            return number\n",
        "\n",
        "extract_mobile_number(text)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'66-4445-5003'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRUMBi-MlS6A"
      },
      "source": [
        "# Extract Email-ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juVa6cGJ9bnN",
        "outputId": "7ee62164-9c4f-4f9b-efac-3727f4af5d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import re\n",
        "\n",
        "def extract_email(email):\n",
        "    email = re.findall(\"([^@|\\s]+@[^@]+\\.[^@|\\s]+)\", email)\n",
        "    if email:\n",
        "        try:\n",
        "            return email[0].split()[0].strip(';')\n",
        "        except IndexError:\n",
        "            return None\n",
        "\n",
        "extract_email(text)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'michael@gmail.com'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "led6aIwamJ0o"
      },
      "source": [
        "# Extract Skills"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_UPEaEF9btc",
        "outputId": "61d5abe7-db5b-4364-d1c7-4090fd6d9825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "# load pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nc = nlp(text)\n",
        "noun_chunks = nc.noun_chunks\n",
        "def extract_skills(resume_text):\n",
        "    nlp_text = nlp(resume_text)\n",
        "\n",
        "    # removing stop words and implementing word tokenization\n",
        "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
        "    \n",
        "    # reading the csv file\n",
        "    data = pd.read_csv(\"techskill.csv\") \n",
        "    \n",
        "    # extract values\n",
        "    skills = list(data.columns.values)\n",
        "    \n",
        "    skillset = []\n",
        "    \n",
        "    # check for one-grams (example: python)\n",
        "    for token in tokens:\n",
        "        if token.lower() in skills:\n",
        "            skillset.append(token)\n",
        "    \n",
        "    # check for bi-grams and tri-grams (example: machine learning)\n",
        "    for token in noun_chunks:\n",
        "        token = token.text.lower().strip()\n",
        "        if token in skills:\n",
        "            skillset.append(token)\n",
        "    \n",
        "    return [i.capitalize() for i in set([i.lower() for i in skillset])]\n",
        "\n",
        "extract_skills(text)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Warehouse', 'C', 'Sql', 'Schema', 'C#', 'Schedule', 'Metrics']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgbjj9nj22sv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}